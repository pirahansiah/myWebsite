{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: listen tcp 127.0.0.1:11434: bind: address already in use\n",
      "NAME                     ID              SIZE      MODIFIED       \n",
      "llava:7b-v1.6            8dd30f6b0cb1    4.7 GB    7 minutes ago     \n",
      "gemma:2b                 b50d6c999e59    1.7 GB    12 minutes ago    \n",
      "llava:latest             8dd30f6b0cb1    4.7 GB    2 months ago      \n",
      "reflection:latest        795e433dda61    39 GB     4 months ago      \n",
      "deepseek-coder:latest    3ddd2d3fc8d2    776 MB    4 months ago      \n",
      "llama3.1:latest          75382d0899df    4.7 GB    5 months ago      \n",
      "\u001b[?25lpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 170370233dd5... 100% ▕████████████████▏ 4.1 GB                         \n",
      "pulling 72d6f08a42f6... 100% ▕████████████████▏ 624 MB                         \n",
      "pulling 43070e2d4e53... 100% ▕████████████████▏  11 KB                         \n",
      "pulling c43332387573... 100% ▕████████████████▏   67 B                         \n",
      "pulling ed11eda7790d... 100% ▕████████████████▏   30 B                         \n",
      "pulling 7c658f9561e5... 100% ▕████████████████▏  564 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n",
      "Error: listen tcp 127.0.0.1:11434: bind: address already in use\n",
      "ollama    5058 farshid    3u  IPv4 0xfec72831d268881b      0t0  TCP 127.0.0.1:11434 (LISTEN)\n"
     ]
    }
   ],
   "source": [
    "#!conda activate farshid\n",
    "\n",
    "#!git clone https://github.com/facebookresearch/segment-anything.git\n",
    "#!cd segment-anything\n",
    "#!pip install .\n",
    "\n",
    "#\n",
    "#!pip uninstall opencv-python\n",
    "#!pip install opencv-python-headless\n",
    "#!pip install torch torchvision torchaudio\n",
    "#!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
    "#!ollama list\n",
    "#!ollama pull llava:7b-v1.6\n",
    "\n",
    "!export OLLAMA_HOST=127.0.0.1:12345\n",
    "!OLLAMA_METAL=true ollama serve\n",
    "!export OPENCV_OPENCL_RUNTIME=1\n",
    "!ollama serve\n",
    "!lsof -nP -iTCP:11434 | grep LISTEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/sam_vit_h_4b8939.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m sam_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/path/to/sam_vit_h_4b8939.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Ensure this path is correct\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvit_h\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m sam \u001b[38;5;241m=\u001b[39m \u001b[43msam_model_registry\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msam_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m mask_generator \u001b[38;5;241m=\u001b[39m SamAutomaticMaskGenerator(sam)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_frame\u001b[39m(b64):\n",
      "File \u001b[0;32m~/projects/install/miniconda3/envs/farshid/lib/python3.12/site-packages/segment_anything/build_sam.py:15\u001b[0m, in \u001b[0;36mbuild_sam_vit_h\u001b[0;34m(checkpoint)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_sam_vit_h\u001b[39m(checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_sam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_embed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1280\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_num_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_global_attn_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m23\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m31\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/install/miniconda3/envs/farshid/lib/python3.12/site-packages/segment_anything/build_sam.py:104\u001b[0m, in \u001b[0;36m_build_sam\u001b[0;34m(encoder_embed_dim, encoder_depth, encoder_num_heads, encoder_global_attn_indexes, checkpoint)\u001b[0m\n\u001b[1;32m    102\u001b[0m sam\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    105\u001b[0m         state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    106\u001b[0m     sam\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/sam_vit_h_4b8939.pth'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "\n",
    "# Load the SAM model\n",
    "sam_checkpoint = \"/path/to/sam_vit_h_4b8939.pth\"  # Ensure this path is correct\n",
    "model_type = \"vit_h\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "def analyze_frame(b64):\n",
    "    url = \"http://localhost:11434/api/generate\"\n",
    "    prompt = \"Please analyze this object's appearance and actions in detail.\"\n",
    "    data = {\n",
    "        \"model\": \"llava:7b-v1.6\",\n",
    "        \"prompt\": prompt,\n",
    "        \"images\": [b64],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=data)\n",
    "        response_json = response.json()\n",
    "        if \"error\" in response_json:\n",
    "            return f\"Error: {response_json['error']}\"\n",
    "        return response_json.get(\"response\", \"No response\")\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def frame_to_base64(frame):\n",
    "    # Convert the frame to RGB\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(frame_rgb)\n",
    "    \n",
    "    # Resize the image if necessary\n",
    "    max_size = 1024\n",
    "    if image.width > max_size or image.height > max_size:\n",
    "        ratio = max_size / max(image.width, image.height)\n",
    "        new_size = (int(image.width * ratio), int(image.height * ratio))\n",
    "        image = image.resize(new_size, Image.LANCZOS)\n",
    "    \n",
    "    # Convert the image to base64\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"JPEG\", quality=85)\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def track_object(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    output = []\n",
    "    frame_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process every second (assuming fps is the frame rate)\n",
    "        if frame_count % int(fps) == 0:\n",
    "            # Convert frame to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Generate masks\n",
    "            masks = mask_generator.generate(frame_rgb)\n",
    "            \n",
    "            if masks:\n",
    "                # Get the largest mask\n",
    "                largest_mask = max(masks, key=lambda x: x[\"area\"])[\"segmentation\"]\n",
    "                \n",
    "                # Convert frame to base64\n",
    "                frame_b64 = frame_to_base64(frame)\n",
    "                \n",
    "                # Analyze the frame\n",
    "                analysis = analyze_frame(frame_b64)\n",
    "                \n",
    "                # Store the result\n",
    "                output.append({\n",
    "                    \"frame\": frame_count,\n",
    "                    \"timestamp\": frame_count / fps,\n",
    "                    \"analysis\": analysis\n",
    "                })\n",
    "            \n",
    "            time.sleep(1)  # Optional: Add delay to avoid overloading the system\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    return output\n",
    "\n",
    "# Path to the video file\n",
    "video_path = \"/Users/farshid/projects/videos-iran-old-image-arosi/2024-07-09 11:09:37.228/mimos-devbox-11.MOV\"\n",
    "\n",
    "# Process the video\n",
    "results = track_object(video_path)\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open(\"video_analysis.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    print(f\"\\nFrame {result['frame']} (Timestamp: {result['timestamp']:.2f}s)\\nAnalysis: {result['analysis']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Anything library is installed and imported successfully!\n"
     ]
    }
   ],
   "source": [
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "print(\"Segment Anything library is installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 29.982395160926284\n",
      "Total frames: 1107\n",
      "Processing frame 0\n",
      "\n",
      "Frame 0 (Timestamp: 0.00s)\n",
      "Analysis:  In the image, there is a focus on a gaming computer setup with a monitor displaying the startup screen of a computer system. On this screen, we can see the logo for GeForce and the text \"GeForce GTX 1650\" at the top, followed by the Nvidia logo at the bottom center. Below the Nvidia logo, there are three rows of text. The first row reads \"GeForce GTX,\" followed by \"1650\" below it. The second row contains \"GeForce GTX\" again, and the third row also repeats the \"GeForce GTX\" text, but with a different font size and style than the other two rows.\n",
      "\n",
      "The monitor is situated on a desk, which has various items on it. To the left of the monitor, there appears to be a keyboard with visible keys such as \"Shift,\" \"Ctrl,\" \"Alt,\" and some letters and numbers. Below the monitor, there are several graphics cards (GPUs) in a vertical arrangement, including at least one GeForce GTX 1650 card. Each GPU has its own cooling fan, and all of them have their branding visible.\n",
      "\n",
      "On the right side of the image, partially obscured by the monitor and the GPU setup, there is a person's arm with a tattoo or marking on it. The individual holding the camera is not fully visible; only the arm and part of the camera are shown.\n",
      "\n",
      "The environment surrounding the computer setup suggests that this could be a gaming station in a home or an office setting. There are no texts outside the monitor that provide additional context about the specific model or brand of the monitor itself, nor any other visible text. The actions and movements captured in this image seem to focus on the display of the GeForce GTX 1650 graphics card and its associated branding. \n"
     ]
    }
   ],
   "source": [
    "# working video\n",
    "import cv2,base64,requests,json,time\n",
    "from PIL import Image\n",
    "import io\n",
    "def extract_frame_info(frame_base64):\n",
    "    url=\"http://localhost:11434/api/generate\"\n",
    "    prompt=\"\"\"Please analyze this frame and describe:\n",
    "    1. What's happening in this frame\n",
    "    2. Any visible text (OCR)\n",
    "    3. Key objects and people\n",
    "    4. Actions and movements\n",
    "    5. Environmental details\n",
    "    Be very specific and detailed.\"\"\"\n",
    "    payload={\"model\":\"llava:7b-v1.6\",\"prompt\":prompt,\"images\":[frame_base64],\"stream\":False}\n",
    "    try:\n",
    "        r=requests.post(url,json=payload)\n",
    "        j=r.json()\n",
    "        if\"error\"in j:return f\"Error: {j['error']}\"\n",
    "        return j.get(\"response\",\"No response received\")\n",
    "    except Exception as e:\n",
    "        return f\"Error processing frame: {e}\"\n",
    "def frame_to_base64(frame):\n",
    "    fr=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    im=Image.fromarray(fr)\n",
    "    mx=1024\n",
    "    if im.width>mx or im.height>mx:\n",
    "        ratio=mx/max(im.width,im.height)\n",
    "        ns=(int(im.width*ratio),int(im.height*ratio))\n",
    "        im=im.resize(ns,Image.LANCZOS)\n",
    "    b=io.BytesIO()\n",
    "    im.save(b,format=\"JPEG\",quality=85)\n",
    "    return base64.b64encode(b.getvalue()).decode(\"utf-8\")\n",
    "def analyze_video(v):\n",
    "    c=cv2.VideoCapture(v)\n",
    "    f=c.get(cv2.CAP_PROP_FPS)\n",
    "    fc=int(c.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Video FPS: {f}\")\n",
    "    print(f\"Total frames: {fc}\")\n",
    "    a=[]\n",
    "    n=0\n",
    "    while c.isOpened():\n",
    "        r,fr=c.read()\n",
    "        if not r:break\n",
    "        if n%int(f*60)==0:\n",
    "            print(f\"Processing frame {n}\")\n",
    "            b=frame_to_base64(fr)\n",
    "            an=extract_frame_info(b)\n",
    "            d={\"frame_number\":n,\"timestamp\":n/f,\"analysis\":an}\n",
    "            a.append(d)\n",
    "            time.sleep(1)\n",
    "        n+=1\n",
    "    c.release()\n",
    "    return a\n",
    "p=\"/Users/farshid/projects/videos-iran-old-image-arosi/2024-07-09 11:09:37.228/mimos-devbox-11.MOV\"\n",
    "r=analyze_video(p)\n",
    "with open(\"video_analysis.json\",\"w\")as f:\n",
    "    json.dump(r,f,indent=4)\n",
    "for fr in r:\n",
    "    print(f\"\\nFrame {fr['frame_number']} (Timestamp: {fr['timestamp']:.2f}s)\")\n",
    "    print(\"Analysis:\",fr[\"analysis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:  Hello there! It's nice to meet you. How can I assist you today? \n"
     ]
    }
   ],
   "source": [
    "# working\n",
    "import requests\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "payload = {\n",
    "   \"model\": \"llava:7b-v1.6\", \n",
    "   \"prompt\": \"Hello from the llava:7b-v1.6 model!\",\n",
    "   \"stream\": False\n",
    "}\n",
    "response = requests.post(url, json=payload)\n",
    "print(\"Model response:\", response.json()[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- RAW MODEL OUTPUT -----\n",
      " ```json\n",
      "{\n",
      "  \"function_call\": \"display_cities\",\n",
      "  \"arguments\": {\n",
      "    \"preferences\": \"skiing\",\n",
      "    \"cities\": [\"Aspen, CO\", \"Vail, CO\", \"Park City, UT\"]\n",
      "  }\n",
      "}\n",
      "``` \n",
      "--------------------------------\n",
      "\n",
      "Function Name: display_cities\n",
      "Preferences: skiing\n",
      "Recommended Cities: ['Aspen, CO', 'Vail, CO', 'Park City, UT']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "def display_cities(cities: list[str], preferences: Optional[str] = None):\n",
    "   return cities\n",
    "\n",
    "prompt_text = (\n",
    "   \"You are a helpful assistant. A user wants to take a ski trip with their family \"\n",
    "   \"but isn't sure where to go. Return a JSON snippet with two keys: 'preferences' \"\n",
    "   \"set to 'skiing' and 'cities' set to a list of recommended ski destinations. \"\n",
    "   \"Use this format:\\n\"\n",
    "   \"{\\n\"\n",
    "   \"  \\\"function_call\\\": \\\"display_cities\\\",\\n\" \n",
    "   \"  \\\"arguments\\\": {\\n\"\n",
    "   \"    \\\"preferences\\\": \\\"...\\\",\\n\"\n",
    "   \"    \\\"cities\\\": [\\\"...\\\", \\\"...\\\", \\\"...\\\"]\\n\"\n",
    "   \"  }\\n\"\n",
    "   \"}\\n\"\n",
    "   \"Only return valid JSON, no extra commentary.\"\n",
    ")\n",
    "\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "payload = {\n",
    "   \"model\": \"llava:7b-v1.6\",\n",
    "   \"prompt\": prompt_text,\n",
    "   \"stream\": False\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "model_output = response.json()[\"response\"]\n",
    "print(\"----- RAW MODEL OUTPUT -----\")\n",
    "print(model_output)\n",
    "print(\"--------------------------------\\n\")\n",
    "\n",
    "# Clean up the model output to extract just the JSON part\n",
    "json_start = model_output.find('{')\n",
    "json_end = model_output.rfind('}') + 1\n",
    "clean_json = model_output[json_start:json_end].replace(';', ',')\n",
    "\n",
    "function_data = json.loads(clean_json)\n",
    "function_name = function_data[\"function_call\"]\n",
    "function_args = function_data[\"arguments\"]\n",
    "\n",
    "# Convert single string of cities to list\n",
    "if isinstance(function_args[\"cities\"], str):\n",
    "   function_args[\"cities\"] = [city.strip() for city in function_args[\"cities\"][1:-1].split(',')]\n",
    "\n",
    "recommended_cities = display_cities(\n",
    "   cities=function_args[\"cities\"],\n",
    "   preferences=function_args[\"preferences\"]\n",
    ")\n",
    "\n",
    "print(f\"Function Name: {function_name}\")\n",
    "print(f\"Preferences: {function_args['preferences']}\")\n",
    "print(f\"Recommended Cities: {recommended_cities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 29.982395160926284\n",
      "Total frames: 1107\n",
      "Processing frame 0\n",
      "Processing frame 29\n",
      "Processing frame 58\n",
      "Processing frame 87\n",
      "Processing frame 116\n",
      "Processing frame 145\n",
      "Processing frame 174\n",
      "Processing frame 203\n",
      "Processing frame 232\n",
      "Processing frame 261\n",
      "Processing frame 290\n",
      "Processing frame 319\n",
      "Processing frame 348\n",
      "Processing frame 377\n",
      "Processing frame 406\n",
      "Processing frame 435\n",
      "Processing frame 464\n",
      "Processing frame 493\n",
      "Processing frame 522\n",
      "Processing frame 551\n",
      "Processing frame 580\n",
      "Processing frame 609\n",
      "Processing frame 638\n",
      "Processing frame 667\n",
      "Processing frame 696\n",
      "Processing frame 725\n",
      "Processing frame 754\n",
      "Processing frame 783\n",
      "Processing frame 812\n",
      "Processing frame 841\n",
      "Processing frame 870\n",
      "Processing frame 899\n",
      "Processing frame 928\n",
      "Processing frame 957\n",
      "Processing frame 986\n",
      "Processing frame 1015\n",
      "Processing frame 1044\n",
      "Processing frame 1073\n",
      "Processing frame 1102\n",
      "\n",
      "Frame 0 (Timestamp: 0.00s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 29 (Timestamp: 0.97s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 58 (Timestamp: 1.93s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 87 (Timestamp: 2.90s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 116 (Timestamp: 3.87s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 145 (Timestamp: 4.84s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 174 (Timestamp: 5.80s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 203 (Timestamp: 6.77s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 232 (Timestamp: 7.74s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 261 (Timestamp: 8.71s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 290 (Timestamp: 9.67s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 319 (Timestamp: 10.64s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 348 (Timestamp: 11.61s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 377 (Timestamp: 12.57s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 406 (Timestamp: 13.54s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 435 (Timestamp: 14.51s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 464 (Timestamp: 15.48s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 493 (Timestamp: 16.44s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 522 (Timestamp: 17.41s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 551 (Timestamp: 18.38s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 580 (Timestamp: 19.34s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 609 (Timestamp: 20.31s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 638 (Timestamp: 21.28s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 667 (Timestamp: 22.25s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 696 (Timestamp: 23.21s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 725 (Timestamp: 24.18s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 754 (Timestamp: 25.15s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 783 (Timestamp: 26.12s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 812 (Timestamp: 27.08s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 841 (Timestamp: 28.05s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 870 (Timestamp: 29.02s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 899 (Timestamp: 29.98s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 928 (Timestamp: 30.95s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 957 (Timestamp: 31.92s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 986 (Timestamp: 32.89s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 1015 (Timestamp: 33.85s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 1044 (Timestamp: 34.82s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 1073 (Timestamp: 35.79s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n",
      "\n",
      "Frame 1102 (Timestamp: 36.75s)\n",
      "Analysis: Error: json: cannot unmarshal object into Go struct field GenerateRequest.images of type api.ImageData\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "from PIL import Image\n",
    "import io\n",
    "import time\n",
    "\n",
    "def extract_frame_info(frame_base64):\n",
    "   url = \"http://localhost:11434/api/generate\"\n",
    "   prompt = \"\"\"Please analyze this frame and describe:\n",
    "   1. What's happening in this frame\n",
    "   2. Any visible text (OCR)\n",
    "   3. Key objects and people\n",
    "   4. Actions and movements\n",
    "   5. Environmental details\n",
    "   Be very specific and detailed.\"\"\"\n",
    "   \n",
    "   payload = {\n",
    "       \"model\": \"llava:7b-v1.6\",\n",
    "       \"prompt\": prompt,\n",
    "       \"images\": [{\"data\": frame_base64}],\n",
    "       \"stream\": False\n",
    "   }\n",
    "   \n",
    "   try:\n",
    "       response = requests.post(url, json=payload)\n",
    "       response_json = response.json()\n",
    "       if 'error' in response_json:\n",
    "           return f\"Error: {response_json['error']}\"\n",
    "       return response_json.get('response', 'No response received')\n",
    "   except Exception as e:\n",
    "       return f\"Error processing frame: {str(e)}\"\n",
    "\n",
    "def frame_to_base64(frame):\n",
    "   frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "   pil_image = Image.fromarray(frame_rgb)\n",
    "   \n",
    "   # Resize image if too large\n",
    "   max_size = 1024\n",
    "   if pil_image.width > max_size or pil_image.height > max_size:\n",
    "       ratio = max_size / max(pil_image.width, pil_image.height)\n",
    "       new_size = (int(pil_image.width * ratio), int(pil_image.height * ratio))\n",
    "       pil_image = pil_image.resize(new_size, Image.LANCZOS)\n",
    "   \n",
    "   buffer = io.BytesIO()\n",
    "   pil_image.save(buffer, format=\"JPEG\", quality=85)\n",
    "   return base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "\n",
    "def analyze_video(video_path):\n",
    "   cap = cv2.VideoCapture(video_path)\n",
    "   fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "   frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "   \n",
    "   print(f\"Video FPS: {fps}\")\n",
    "   print(f\"Total frames: {frame_count}\")\n",
    "   \n",
    "   frame_analysis = []\n",
    "   frame_number = 0\n",
    "   \n",
    "   while cap.isOpened():\n",
    "       ret, frame = cap.read()\n",
    "       if not ret:\n",
    "           break\n",
    "           \n",
    "       if frame_number % int(fps*60) == 0:  # Process 1 frame per second\n",
    "           print(f\"Processing frame {frame_number}\")\n",
    "           frame_base64 = frame_to_base64(frame)\n",
    "           analysis = extract_frame_info(frame_base64)\n",
    "           \n",
    "           frame_data = {\n",
    "               \"frame_number\": frame_number,\n",
    "               \"timestamp\": frame_number/fps,\n",
    "               \"analysis\": analysis\n",
    "           }\n",
    "           frame_analysis.append(frame_data)\n",
    "           time.sleep(1)  # Add delay to prevent rate limiting\n",
    "           \n",
    "       frame_number += 1\n",
    "       \n",
    "   cap.release()\n",
    "   return frame_analysis\n",
    "\n",
    "# Process the video\n",
    "video_path = \"/Users/farshid/projects/videos-iran-old-image-arosi/2024-07-09 11:09:37.228/mimos-devbox-11.MOV\"\n",
    "results = analyze_video(video_path)\n",
    "\n",
    "# Save results to file\n",
    "with open('video_analysis.json', 'w') as f:\n",
    "   json.dump(results, f, indent=4)\n",
    "\n",
    "# Print results\n",
    "for frame in results:\n",
    "   print(f\"\\nFrame {frame['frame_number']} (Timestamp: {frame['timestamp']:.2f}s)\")\n",
    "   print(\"Analysis:\", frame['analysis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama  4409 farshid    3u  IPv4 0x404da011551d94ce      0t0  TCP 127.0.0.1:11434 (LISTEN)\n"
     ]
    }
   ],
   "source": [
    "!lsof -nP -iTCP:11434 | grep LISTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3006066127.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    kill  ollama\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "kill  ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     ID              SIZE      MODIFIED       \n",
      "gemma:2b                 b50d6c999e59    1.7 GB    42 seconds ago    \n",
      "llava:latest             8dd30f6b0cb1    4.7 GB    2 months ago      \n",
      "llava:7b-v1.6            8dd30f6b0cb1    4.7 GB    2 months ago      \n",
      "reflection:latest        795e433dda61    39 GB     4 months ago      \n",
      "deepseek-coder:latest    3ddd2d3fc8d2    776 MB    4 months ago      \n",
      "llama3.1:latest          75382d0899df    4.7 GB    5 months ago      \n",
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling c1864a5eb193... 100% ▕████████████████▏ 1.7 GB                         \n",
      "pulling 097a36493f71... 100% ▕████████████████▏ 8.4 KB                         \n",
      "pulling 109037bec39c... 100% ▕████████████████▏  136 B                         \n",
      "pulling 22a838ceb7fb... 100% ▕████████████████▏   84 B                         \n",
      "pulling 887433b89a90... 100% ▕████████████████▏  483 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n",
      "Error: listen tcp 127.0.0.1:11434: bind: address already in use\n"
     ]
    }
   ],
   "source": [
    "!ollama list\n",
    "!ollama pull gemma:2b\n",
    "#!ollama serve\n",
    "!export OLLAMA_LISTEN=127.0.0.1:12345\n",
    "!ollama serve \n",
    "!lsof -nP -iTCP:11411 | grep LISTEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: HTTPConnectionPool(host='localhost', port=11411): Max retries exceeded with url: /completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x141010650>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# The prompt you want to use\n",
    "prompt_text = \"Hello from the gemma:2b model!\"\n",
    "\n",
    "# Ollama server endpoint\n",
    "url = \"http://localhost:11411/completions\"\n",
    "\n",
    "# JSON payload specifying the model and the prompt\n",
    "payload = {\n",
    "    \"model\": \"gemma:2b\",\n",
    "    \"prompt\": prompt_text\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, json=payload)\n",
    "    data = response.json()\n",
    "    print(\"Model response:\", data[\"choices\"][0][\"text\"])\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: HTTPConnectionPool(host='localhost', port=11411): Max retries exceeded with url: /completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x141010890>: Failed to establish a new connection: [Errno 61] Connection refused'))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "# 1. Define your function (identical to your original definition)\n",
    "def display_cities(cities: list[str], preferences: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Provides a list of cities based on the user's search query and preferences.\n",
    "    Args:\n",
    "        preferences (str): The user's preferences for the search, like skiing,\n",
    "                           beach, restaurants, bbq, etc.\n",
    "        cities (list[str]): The list of cities being recommended to the user.\n",
    "    Returns:\n",
    "        list[str]: The list of cities being recommended to the user.\n",
    "    \"\"\"\n",
    "    return cities\n",
    "\n",
    "# 2. Define a prompt that asks the model for suggestions\n",
    "prompt_text = (\n",
    "    \"You are a helpful assistant. A user wants to take a ski trip with their family \"\n",
    "    \"but isn’t sure where to go. Return a JSON snippet with two keys: 'preferences' \"\n",
    "    \"set to 'skiing' and 'cities' set to a list of recommended ski destinations. \"\n",
    "    \"Use this format:\\n\"\n",
    "    \"{\\n\"\n",
    "    \"  \\\"function_call\\\": \\\"display_cities\\\",\\n\"\n",
    "    \"  \\\"arguments\\\": {\\n\"\n",
    "    \"    \\\"preferences\\\": \\\"...\\\",\\n\"\n",
    "    \"    \\\"cities\\\": [\\\"...\\\", \\\"...\\\", \\\"...\\\"]\\n\"\n",
    "    \"  }\\n\"\n",
    "    \"}\\n\"\n",
    "    \"Only return valid JSON, no extra commentary.\"\n",
    ")\n",
    "\n",
    "# 3. Make a POST request to the Ollama server with the gemma:2b model\n",
    "url = \"http://localhost:11411/completions\"\n",
    "payload = {\n",
    "    \"model\": \"gemma:2b\",\n",
    "    \"prompt\": prompt_text\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, json=payload, timeout=180)\n",
    "    data = response.json()\n",
    "\n",
    "    # The model's text output (hopefully a JSON string)\n",
    "    model_output = data.get(\"choices\", [{}])[0].get(\"text\", \"\")\n",
    "\n",
    "    print(\"----- RAW MODEL OUTPUT -----\")\n",
    "    print(model_output)\n",
    "    print(\"--------------------------------\\n\")\n",
    "\n",
    "    # 4. Parse the JSON portion from the model’s text\n",
    "    import json\n",
    "\n",
    "    # Attempt to parse the JSON returned by the model\n",
    "    function_data = json.loads(model_output)\n",
    "\n",
    "    function_name = function_data[\"function_call\"]\n",
    "    function_args = function_data[\"arguments\"]\n",
    "\n",
    "    # 5. Call the Python function with the extracted arguments\n",
    "    recommended_cities = display_cities(\n",
    "        cities=function_args[\"cities\"],\n",
    "        preferences=function_args[\"preferences\"]\n",
    "    )\n",
    "\n",
    "    # 6. Print results\n",
    "    print(f\"Function Name: {function_name}\")\n",
    "    print(f\"Preferences: {function_args['preferences']}\")\n",
    "    print(f\"Recommended Cities: {recommended_cities}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "farshid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
